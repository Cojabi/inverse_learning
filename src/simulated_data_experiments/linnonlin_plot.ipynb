{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbirkenbihl/git/Cog_resilience/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from simulation_utils import run_std_approach, run_my_lin\n",
    "from DataGenerator import DataGenerator\n",
    "from constants_sim import RANDOM_SEED, PARAMS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from constants import CV_FOLDS, OPTUNA__N_TRIALS, OPTUNA__N_JOBS, XGB__NTHREAD, \\\n",
    "    N_ESTIMATORS, EARLY_STOPPING_ROUNDS, OBJECTIVE, XGB_HP\n",
    "from utils import aggregate_results, aggregate_feature_importances, \\\n",
    "    aggregate_residuals\n",
    "from plotting import plot_reg_perf, feature_importance_plot, approach_comparison_plot\n",
    "from residual_regressor import ErrorRegressor\n",
    "from xgb.experiment import XGBoostExperiment\n",
    "from xgb.final_model import FinalXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(152)\n",
    "net_residual = nn.Sequential(\n",
    "    nn.Linear(PARAMS['n_informative']*3, 16),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(16, 82),\n",
    "    nn.BatchNorm1d(82),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(82, 32),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.BatchNorm1d(8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.BatchNorm1d(4),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(4, 1),\n",
    "    nn.BatchNorm1d(1),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear GT, non-linear res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.635899</td>\n",
       "      <td>-16.447328</td>\n",
       "      <td>-14.088288</td>\n",
       "      <td>-24.337356</td>\n",
       "      <td>-4.757166</td>\n",
       "      <td>-7.864151</td>\n",
       "      <td>2.866112</td>\n",
       "      <td>30.917436</td>\n",
       "      <td>-0.461558</td>\n",
       "      <td>11.083579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373478</td>\n",
       "      <td>5.550740</td>\n",
       "      <td>21.187584</td>\n",
       "      <td>0.679776</td>\n",
       "      <td>18.509377</td>\n",
       "      <td>10.013308</td>\n",
       "      <td>-3.575150</td>\n",
       "      <td>-10.795736</td>\n",
       "      <td>10.410479</td>\n",
       "      <td>-10.569935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.326742</td>\n",
       "      <td>0.863992</td>\n",
       "      <td>-2.042409</td>\n",
       "      <td>-20.567818</td>\n",
       "      <td>6.033498</td>\n",
       "      <td>2.843033</td>\n",
       "      <td>-16.894558</td>\n",
       "      <td>-15.807082</td>\n",
       "      <td>-11.185714</td>\n",
       "      <td>1.452902</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.958734</td>\n",
       "      <td>-35.921324</td>\n",
       "      <td>-16.431890</td>\n",
       "      <td>25.095278</td>\n",
       "      <td>-8.339024</td>\n",
       "      <td>-14.883707</td>\n",
       "      <td>22.814836</td>\n",
       "      <td>7.157325</td>\n",
       "      <td>-12.045748</td>\n",
       "      <td>4.198076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.962641</td>\n",
       "      <td>-15.583336</td>\n",
       "      <td>-16.130696</td>\n",
       "      <td>-44.905174</td>\n",
       "      <td>1.276332</td>\n",
       "      <td>-5.021118</td>\n",
       "      <td>-14.028446</td>\n",
       "      <td>15.110354</td>\n",
       "      <td>-11.647272</td>\n",
       "      <td>12.536481</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.332212</td>\n",
       "      <td>-30.370583</td>\n",
       "      <td>4.755694</td>\n",
       "      <td>25.775054</td>\n",
       "      <td>10.170353</td>\n",
       "      <td>-4.870399</td>\n",
       "      <td>19.239686</td>\n",
       "      <td>-3.638411</td>\n",
       "      <td>-1.635269</td>\n",
       "      <td>-6.371859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        330        331        332        333       334       335        336  \\\n",
       "0 -6.635899 -16.447328 -14.088288 -24.337356 -4.757166 -7.864151   2.866112   \n",
       "1 -2.326742   0.863992  -2.042409 -20.567818  6.033498  2.843033 -16.894558   \n",
       "2 -8.962641 -15.583336 -16.130696 -44.905174  1.276332 -5.021118 -14.028446   \n",
       "\n",
       "         337        338        339  ...       990        991        992  \\\n",
       "0  30.917436  -0.461558  11.083579  ... -0.373478   5.550740  21.187584   \n",
       "1 -15.807082 -11.185714   1.452902  ... -2.958734 -35.921324 -16.431890   \n",
       "2  15.110354 -11.647272  12.536481  ... -3.332212 -30.370583   4.755694   \n",
       "\n",
       "         993        994        995        996        997        998        999  \n",
       "0   0.679776  18.509377  10.013308  -3.575150 -10.795736  10.410479 -10.569935  \n",
       "1  25.095278  -8.339024 -14.883707  22.814836   7.157325 -12.045748   4.198076  \n",
       "2  25.775054  10.170353  -4.870399  19.239686  -3.638411  -1.635269  -6.371859  \n",
       "\n",
       "[3 rows x 670 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "dg = DataGenerator(random_seed=RANDOM_SEED)\n",
    "X_train, y_train, X_test, y_test, y_test_no_coi, res_proportion, coefs, res_coefs = dg.generate_linear_data(**PARAMS)\n",
    "\n",
    "fig_name = f'form_linnonlin_{PARAMS[\"effective_rank\"]}rank_{PARAMS[\"n_common\"]}common_{PARAMS[\"noise\"]}noise_{PARAMS[\"n_informative\"]}_\\\n",
    "informative_res_coef{PARAMS[\"res_coef_value\"]}_gt_coef{PARAMS[\"gt_coef_value\"]}'\n",
    "data_save_path = \"../../../sent/simulated/sim_lin_nonlin\"\n",
    "\n",
    "X_test_nn = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "res_proportion_linnonlin = net_residual(X_test_nn).detach().numpy().flatten() * 3\n",
    "y_test = y_test_no_coi + res_proportion\n",
    "\n",
    "pd.DataFrame([y_test_no_coi, res_proportion, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_results = run_std_approach(X_train, y_train, X_test, y_test, combine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My approach Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylin_results = run_my_lin(X_train, X_test, y_train, y_test, with_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(res_proportion, open(f'{data_save_path}/res_proportion.p', 'wb'))\n",
    "pickle.dump(std_results, open(f'{data_save_path}/std_results.p', 'wb'))\n",
    "pickle.dump(mylin_results, open(f'{data_save_path}/mylin_results.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTUNA__N_TRIALS = 50\n",
    "REPEATS = 3\n",
    "NUMERICAL = X_train.columns\n",
    "\n",
    "# Create the directory for the xgboost results\n",
    "xgb_save_path = f\"../../../sent/simulated/sim_lin_nonlin/xgboost_exp\"\n",
    "os.makedirs(xgb_save_path, exist_ok=True)\n",
    "\n",
    "exp = XGBoostExperiment(xgb_save_path, X_train, y_train, NUMERICAL, [], CV_FOLDS,\n",
    "                        OBJECTIVE, XGB_HP, OPTUNA__N_TRIALS, OPTUNA__N_JOBS,\n",
    "                        XGB__NTHREAD, N_ESTIMATORS, EARLY_STOPPING_ROUNDS)\n",
    "exp.run(repeats=REPEATS)\n",
    "\n",
    "# aggregate the results across repeats\n",
    "mean_result = aggregate_results(xgb_save_path)\n",
    "mean_result.to_csv(f\"{xgb_save_path}/mean_results.out\")\n",
    "res_results = aggregate_residuals(xgb_save_path)\n",
    "res_results.to_csv(f\"{xgb_save_path}/residuals.out\")\n",
    "feat_imps = aggregate_feature_importances(xgb_save_path)\n",
    "# plots\n",
    "feature_importance_plot(feat_imps, xgb_save_path)\n",
    "plot_reg_perf(mean_result, xgb_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:00<00:01,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:01<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_save_path = f\"../../../sent/simulated/sim_lin_nonlin/xgboost_exp\" #use the same HPs as in the all-linear experiment\n",
    "xgbfinal_save_path = f\"../../../sent/simulated/sim_lin_nonlin/xgb_final\"\n",
    "os.makedirs(xgbfinal_save_path, exist_ok=True)\n",
    "\n",
    "final = FinalXGB(xgbfinal_save_path, X_train, y_train, X_train.columns, [], CV_FOLDS, \n",
    "                OBJECTIVE, XGB_HP, OPTUNA__N_TRIALS, OPTUNA__N_JOBS,\n",
    "                XGB__NTHREAD, N_ESTIMATORS, EARLY_STOPPING_ROUNDS, repeats=5)\n",
    "final.train(exp_glob_pattern=f\"{xgb_save_path}/repeat-*/params.json\")\n",
    "res_test, _ = final.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build error correction model\n",
    "train_res = aggregate_residuals(xgb_save_path)\n",
    "residual_regressor = ErrorRegressor(numerical=X_train.columns, imp_iter=25)\n",
    "residual_regressor.fit(X_train, train_res[\"Residual_mean\"])\n",
    "\n",
    "## Load test data\n",
    "corr_residuals_table = residual_regressor.clean_residuals(X_test, res_test[\"Residual_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corr_residuals_table, open(f'{data_save_path}/res_test.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_results = pickle.load(open(f'{data_save_path}/std_results.p', 'rb'))\n",
    "mylin_results = pickle.load(open(f'{data_save_path}/mylin_results.p', 'rb'))\n",
    "corr_residuals_table = pickle.load(open(f'{data_save_path}/res_test.p', 'rb'))\n",
    "res_proportion = pickle.load(open(f'{data_save_path}/res_prop.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "approach_comparison_plot(res_proportion, std_results[0], mylin_results[0], corr_residuals_table, \n",
    "                         \"True vs extracted residuals (linear gt, non-lin res)\",\n",
    "                         save_path=f\"{data_save_path}/form_linnonlin.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
